{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"Script hit a snag and got an HTTPError 403. Check your log file for more info.\")? (<ipython-input-2-00c1ad77235d>, line 74)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-00c1ad77235d>\"\u001b[1;36m, line \u001b[1;32m74\u001b[0m\n\u001b[1;33m    print \"Script hit a snag and got an HTTPError 403. Check your log file for more info.\"\u001b[0m\n\u001b[1;37m                                                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"Script hit a snag and got an HTTPError 403. Check your log file for more info.\")?\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import sys, os\n",
    "import logging\n",
    "from urllib import HTTPError\n",
    "from ConfigParser import SafeConfigParser\n",
    "\n",
    "\n",
    "# helper function to iterate through dates\n",
    "def daterange( start_date, end_date ):\n",
    "    if start_date <= end_date:\n",
    "        for n in range( ( end_date - start_date ).days + 1 ):\n",
    "            yield start_date + datetime.timedelta( n )\n",
    "    else:\n",
    "        for n in range( ( start_date - end_date ).days + 1 ):\n",
    "            yield start_date - datetime.timedelta( n )\n",
    "\n",
    "# helper function to get json into a form I can work with       \n",
    "def convert(input):\n",
    "    if isinstance(input, dict):\n",
    "        return {convert(key): convert(value) for key, value in input.iteritems()}\n",
    "    elif isinstance(input, list):\n",
    "        return [convert(element) for element in input]\n",
    "    elif isinstance(input, unicode):\n",
    "        return input.encode('utf-8')\n",
    "    else:\n",
    "        return input\n",
    "\n",
    "# helpful function to figure out what to name individual JSON files        \n",
    "def getJsonFileName(date, page, json_file_path):\n",
    "    json_file_name = \".\".join([date,str(page),'json'])\n",
    "    json_file_name = \"\".join([json_file_path,json_file_name])\n",
    "    return json_file_name\n",
    "\n",
    "# helpful function for processing keywords, mostly    \n",
    "def getMultiples(items, key):\n",
    "    values_list = \"\"\n",
    "    if len(items) > 0:\n",
    "        num_keys = 0\n",
    "        for item in items:\n",
    "            if num_keys == 0:\n",
    "                values_list = item[key]                \n",
    "            else:\n",
    "                values_list =  \"; \".join([values_list,item[key]])\n",
    "            num_keys += 1\n",
    "    return values_list\n",
    "    \n",
    "# get the articles from the NYTimes Article API    \n",
    "def getArticles(date, query, api_key, json_file_path):\n",
    "    # LOOP THROUGH THE 101 PAGES NYTIMES ALLOWS FOR THAT DATE\n",
    "    for page in range(101):\n",
    "        for n in range(5): # 5 tries\n",
    "            try:\n",
    "                request_string = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=\" + query + \"&begin_date=\" + date + \"&end_date=\" + date + \"&page=\" + str(page) + \"&api-key=\" + api_key\n",
    "                response = urllib.urlopen(request_string)\n",
    "                content = response.read()\n",
    "                if content:\n",
    "                    articles = convert(json.loads(content))\n",
    "                    # if there are articles here\n",
    "                    if len(articles[\"response\"][\"docs\"]) >= 1:\n",
    "                        json_file_name = getJsonFileName(date, page, json_file_path)\n",
    "                        json_file = open(json_file_name, 'w')\n",
    "                        json_file.write(content)\n",
    "                        json_file.close()\n",
    "                    # if no more articles, go to next date\n",
    "                    else:\n",
    "                        return\n",
    "                time.sleep(3) # wait so we don't overwhelm the API\n",
    "            except HTTPError as e:\n",
    "                logging.error(\"HTTPError on page %s on %s (err no. %s: %s) Here's the URL of the call: %s\", page, date, e.code, e.reason, request_string)\n",
    "                if e.code == 403:\n",
    "                    print \"Script hit a snag and got an HTTPError 403. Check your log file for more info.\"\n",
    "                    return\n",
    "                if e.code == 429:\n",
    "                    print \"Waiting. You've probably reached an API limit.\"\n",
    "                    time.sleep(30) # wait 30 seconds and try again\n",
    "            except: \n",
    "                logging.error(\"Error on %s page %s: %s\", date, file_number, sys.exc_info()[0])\n",
    "                continue\n",
    "\n",
    "# parse the JSON files you stored into a tab-delimited file\n",
    "def parseArticles(date, tsv_file_name, json_file_path):\n",
    "\n",
    "    for file_number in range(101):\n",
    "        # get the articles and put them into a dictionary\n",
    "        try:\n",
    "            file_name = getJsonFileName(date,file_number, json_file_path)\n",
    "            if os.path.isfile(file_name):\n",
    "                in_file = open(file_name, 'r')\n",
    "                articles = convert(json.loads(in_file.read()))\n",
    "                in_file.close()\n",
    "            else:\n",
    "                break\n",
    "        except IOError as e:\n",
    "            logging.error(\"IOError in %s page %s: %s %s\", date, file_number, e.errno, e.strerror)\n",
    "            continue\n",
    "        \n",
    "        # if there are articles in that document, parse them\n",
    "        if len(articles[\"response\"][\"docs\"]) >= 1:  \n",
    "\n",
    "            # open the tsv for appending\n",
    "            try:\n",
    "                out_file = open(tsv_file_name, 'ab')\n",
    "\n",
    "            except IOError as e:\n",
    "                logging.error(\"IOError: %s %s %s %s\", date, file_number, e.errno, e.strerror)\n",
    "                continue\n",
    "        \n",
    "            # loop through the articles putting what we need in a tsv   \n",
    "            try:\n",
    "                for article in articles[\"response\"][\"docs\"]:\n",
    "                    # if (article[\"source\"] == \"The New York Times\" and article[\"document_type\"] == \"article\"):\n",
    "                    keywords = \"\"\n",
    "                    keywords = getMultiples(article[\"keywords\"],\"value\")\n",
    "    \n",
    "                    # should probably pull these if/else checks into a module\n",
    "                    variables = [\n",
    "                        article[\"pub_date\"], \n",
    "                        keywords, \n",
    "                        str(article[\"headline\"][\"main\"]).decode(\"utf8\").replace(\"\\n\",\"\") if \"main\" in article[\"headline\"].keys() else \"\", \n",
    "                        str(article[\"source\"]).decode(\"utf8\") if \"source\" in article.keys() else \"\", \n",
    "                        str(article[\"document_type\"]).decode(\"utf8\") if \"document_type\" in article.keys() else \"\", \n",
    "                        article[\"web_url\"] if \"web_url\" in article.keys() else \"\",\n",
    "                        str(article[\"news_desk\"]).decode(\"utf8\") if \"news_desk\" in article.keys() else \"\",\n",
    "                        str(article[\"section_name\"]).decode(\"utf8\") if \"section_name\" in article.keys() else \"\",\n",
    "                        str(article[\"snippet\"]).decode(\"utf8\").replace(\"\\n\",\"\") if \"snippet\" in article.keys() else \"\",\n",
    "                        str(article[\"lead_paragraph\"]).decode(\"utf8\").replace(\"\\n\",\"\") if \"lead_paragraph\" in article.keys() else \"\",\n",
    "                        ]\n",
    "                    line = \"\\t\".join(variables)\n",
    "                    out_file.write(line.encode(\"utf8\")+\"\\n\")\n",
    "            except KeyError as e:\n",
    "                logging.error(\"KeyError in %s page %s: %s %s\", date, file_number, e.errno, e.strerror)\n",
    "                continue\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                raise\n",
    "            except: \n",
    "                logging.error(\"Error on %s page %s: %s\", date, file_number, sys.exc_info()[0])\n",
    "                continue\n",
    "        \n",
    "            out_file.close()\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "# Main function where stuff gets done\n",
    "\n",
    "def main():\n",
    "    \n",
    "    config = SafeConfigParser()\n",
    "    script_dir = os.path.dirname(__file__)\n",
    "    config_file = os.path.join(script_dir, 'config/settings.cfg')\n",
    "    config.read(config_file)\n",
    "    \n",
    "    json_file_path = config.get('files','json_folder')\n",
    "    tsv_file_name = config.get('files','tsv_file')\n",
    "    log_file = config.get('files','logfile')\n",
    "    \n",
    "    api_key = config.get('nytimes','api_key')    \n",
    "    start = datetime.date( year = int(config.get('nytimes','start_year')), month = int(config.get('nytimes','start_month')), day = int(config.get('nytimes','start_day')) )\n",
    "    end = datetime.date( year = int(config.get('nytimes','end_year')), month = int(config.get('nytimes','end_month')), day = int(config.get('nytimes','end_day')) )\n",
    "    query = config.get('nytimes','query')\n",
    "        \n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO)\n",
    "    \n",
    "    logging.info(\"Getting started.\") \n",
    "    try:\n",
    "        # LOOP THROUGH THE SPECIFIED DATES\n",
    "        for date in daterange( start, end ):\n",
    "            date = date.strftime(\"%Y%m%d\")\n",
    "            logging.info(\"Working on %s.\" % date)\n",
    "            getArticles(date, query, api_key, json_file_path)\n",
    "            parseArticles(date, tsv_file_name, json_file_path)\n",
    "    except:\n",
    "        logging.error(\"Unexpected error: %s\", str(sys.exc_info()[0]))\n",
    "    finally:\n",
    "        logging.info(\"Finished.\")\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
